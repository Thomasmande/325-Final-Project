---
title: "Proposal EDA"
author: "Thomas Mande"
date: "2022-12-02"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-data}
#install.packages('haven')
library(haven)
sesame <- read_dta("sesame.dta")
library(tidyverse)
library(knitr)
library(broom)
```

```{r}
head(sesame)
```

### Data Cleaning + Super Basic Stats

```{r}
#sesame 1 i'm using for gams
sesame <- sesame %>%
  mutate(viewcat = as.factor(viewcat)) %>%
  mutate(site = as.factor(site)) %>%
  mutate(sex = as.factor(sex)) %>%
  mutate(setting = as.factor(setting)) %>%
  mutate(viewenc = as.factor(viewenc)) %>%
  mutate(regular = as.factor(regular))
sesame1<- sesame
sesame1 <- sesame1 %>%
  mutate(difflet = postlet - prelet) %>%
  mutate(diffnumb = postnumb - prenumb)
```

```{r}
levels(sesame$site) <- c("Disadv City", "Adv Sub", "Adv Rural", "Disadv Rural", "Disadv Spanish")
```


```{r}
sesame <- sesame %>% 
  mutate(diffbody = postbody - prebody) %>% 
  mutate(difflet = postlet - prelet) %>% 
  mutate(diffform = postform - preform) %>% 
  mutate(diffnumb = postnumb - prenumb) %>% 
  mutate(diffrelat = postrelat - prerelat) %>%
  mutate(diffclasf = postclasf - preclasf)
```

```{r}
sesame %>%
  group_by(site) %>%
  count()
```


```{r}
sesame %>%
  group_by(site) %>%
  count(encour)
```

```{r}
sesame %>%
  group_by(viewcat) %>%
  count(encour)
```


### Question 1: Does watching sesame street impact learning?


```{r}
#Created models to look for effects of being in different viewing categories on learning across categories. Seems like two most significant ones are difflet and diffnumb, others not very strong effects

lm_body <- lm(diffbody ~ viewcat, data = sesame)
lm_let <- lm(difflet ~ viewcat, data = sesame)
lm_form <- lm(diffform ~ viewcat, data = sesame)
lm_numb <- lm(diffnumb ~ viewcat, data = sesame)
lm_relat <- lm(diffrelat ~ viewcat, data = sesame)
lm_clasf <- lm(diffclasf ~ viewcat, data = sesame)
summary(lm_body)
summary(lm_let)
summary(lm_form)
summary(lm_numb)
summary(lm_relat)
summary(lm_clasf)
```

```{r}
# Mean in difference in each of these scores by view category
sesame %>%
  group_by(viewcat) %>%
  summarise(mean = mean(diffbody)) 
sesame %>%
  group_by(viewcat) %>%
  summarise(mean = mean(difflet)) 
sesame %>%
  group_by(viewcat) %>%
  summarise(mean = mean(diffform)) 
sesame %>%
  group_by(viewcat) %>%
  summarise(mean = mean(diffnumb)) 
sesame %>%
  group_by(viewcat) %>%
  summarise(mean = mean(diffrelat)) 
sesame %>%
  group_by(viewcat) %>%
  summarise(mean = mean(diffclasf)) 
```


```{r}
#see what happens using regular instead of viewcat. still strongly significant. could maybe try these with all response vars if we are curious
lm_let_reg <- lm(difflet ~ regular, data = sesame)
lm_numb_reg <- lm(diffnumb ~ regular, data = sesame)
summary(lm_let_reg)
summary(lm_numb_reg)
```


```{r}
#Decided to focus in on variables with two strongest effects, and see whether those effects still held up when control for other characteristics. The effects did hold up as significant, but other variables were significant as well. From this, though, it feels fair to include that watching Sesame Street more frequently did result in increased learning about letters and numbers.The models (especially the second one) still have pretty low adjusted R^2's tho, so definitely a lot of room to improve in our predictive power.

#Is there anything else we have to do to show that sesame street generally was associated with increased learning, at least in these two categories?

lm_let <- lm(difflet ~ viewcat + sex + age + setting + + prelet + site, data = sesame)
lm_numb <- lm(diffnumb ~ viewcat + sex + age + setting + + prenumb + site, data = sesame)

summary(lm_let)
summary(lm_numb)
```


### Question 2: How did the benefits of watching sesame street vary across demographic groups?


```{r}
#Continuing focus on difflet and diffnumb, these graphs show how learning varied depending on how much people watched, and start to illustrate potnetial differences between groups

ggplot(data = sesame, mapping = aes(x = viewcat, y = difflet, color = site)) +
  geom_point() +
  labs(title = "Difference in Letter Scores by Viewing Category and Site",
       x = "Viewing Category", y = "Score Difference", color = "Site")
ggplot(data = sesame, mapping = aes(x = viewcat, y = diffnumb, color = site)) +
  geom_point() +
  labs(title = "Difference in Number Scores by Viewing Category and Site",
       x = "Viewing Category", y = "Score Difference", color = "Site")
```

```{r}
#Just made these graphs and I really like them. They confirm the general point that there isn't really an interaction between the sites and how much people's scores are improving--the scores of certain gropus are just generally improving at a higher rate. 

library(ggplot2)
qplot(x = as.numeric(viewcat), y = difflet, data = sesame, color = site) +
  geom_smooth(method = "lm") + labs(title = "")
qplot(x = as.numeric(viewcat), y = diffnumb, data = sesame, color = site) +
  geom_smooth(method = "lm") 
```

```{r}
#related summary stats for all categories
sesame %>%
  group_by(site) %>%
  summarise(mean = mean(diffbody)) 
sesame %>%
  group_by(site) %>%
  summarise(mean = mean(difflet)) 
sesame %>%
  group_by(site) %>%
  summarise(mean = mean(diffform)) 
sesame %>%
  group_by(site) %>%
  summarise(mean = mean(diffnumb)) 
sesame %>%
  group_by(site) %>%
  summarise(mean = mean(diffrelat)) 
sesame %>%
  group_by(site) %>%
  summarise(mean = mean(diffclasf)) 
```
```{r}
#age and difflet, diffnumb, since age was significant in earlier models. don't see much of a correlation
ggplot(data = sesame, mapping = aes(x = age, y = difflet)) +
  geom_point() +
  geom_smooth(method = "lm")
ggplot(data = sesame, mapping = aes(x = age, y = diffnumb)) +
  geom_point() +
  geom_smooth(method = "lm")
```

```{r}
#prelet, prenumb and difflet, diffnumb, since age these were significant in earlier models. seems like there is a general correlation where students who had stronger pre scores improved less.
ggplot(data = sesame, mapping = aes(x = prelet, y = difflet)) +
  geom_point() +
  geom_smooth(method = "lm")
ggplot(data = sesame, mapping = aes(x = prenumb, y = diffnumb)) +
  geom_point() +
  geom_smooth(method = "lm")
```



```{r}
#these give an idea of how groups compared on their intial test scores and how much they improved

ggplot(data = sesame, mapping = aes(x = prelet, y = difflet, color = viewcat)) +
  geom_point() + labs(title = "Distribution of Pretest vs. Improvement for Letters")

ggplot(data = sesame, mapping = aes(x = prenumb, y = diffnumb, color = viewcat)) +
  geom_point() + labs(title = "Distribution of Pretest vs. Improvement for Numbers")
```

```{r}
# Here I was trying to see whether or not any interaction terms are significant. First I tried to create a model with just viewcat, site, and their interaction, and basically nothing in it was significant. Then I added in age and pre scores, which both showed up as significant. Then I added interactions with those, and everything went back to insignificant. My thought was that with that many variables nothing was going to show up as significant, so I tried again below using regular instead of viewcat, but still nothing significant. Interesting result, not really sure what to make of it

lm_let_interact <- lm(difflet ~ viewcat + site + viewcat*site + age + prelet + viewcat*age + viewcat*prelet, data = sesame)
lm_numb_interact <- lm(diffnumb ~ viewcat + site + viewcat*site + age + prenumb + viewcat*age + viewcat * prenumb, data = sesame)

summary(lm_let_interact)
summary(lm_numb_interact)
```

```{r}
lm_let_interact2 <- lm(difflet ~ regular + site + regular*site, data = sesame)
lm_numb_interact2 <- lm(diffnumb ~ regular + site + regular*site, data = sesame)

summary(lm_let_interact2)
summary(lm_numb_interact2)
```
Model Working - Sites:

```{r linear-models-demographic-groups}
site1 <- sesame %>%
  filter(site == "Disadv City")

lm_let_site1 <- lm(difflet ~ viewcat + age + prelet, data = site1)
lm_numb_site1 <- lm(diffnumb ~ viewcat + age + prenumb, data = site1)
summary(lm_let_site1)
summary(lm_numb_site1)
```

```{r}
site2 <- sesame %>%
  filter(site == "Adv Sub")

lm_let_site2 <- lm(difflet ~ viewcat + age + prelet, data = site2)
lm_numb_site2 <- lm(diffnumb ~ viewcat + age + prenumb, data = site2)
summary(lm_let_site2)
summary(lm_numb_site2)
```

```{r}
site3 <- sesame %>%
  filter(site == "Adv Rural")

lm_let_site3 <- lm(difflet ~ viewcat + age + prelet, data = site3)
lm_numb_site3 <- lm(diffnumb ~ viewcat + age + prenumb, data = site3)
summary(lm_let_site3)
summary(lm_numb_site3)
```

```{r}
site4 <- sesame %>%
  filter(site == "Disadv Rural")

lm_let_site4 <- lm(difflet ~ viewcat + age + prelet, data = site4)
lm_numb_site4 <- lm(diffnumb ~ viewcat + age + prenumb, data = site4)
summary(lm_let_site4)
summary(lm_numb_site4)
```

```{r}
site5 <- sesame %>%
  filter(site == "Disadv Spanish")

lm_let_site5 <- lm(difflet ~ viewcat + age + prelet, data = site5)
lm_numb_site5 <- lm(diffnumb ~ viewcat + age + prenumb, data = site5)
summary(lm_let_site5)
summary(lm_numb_site5)
```

```{r}
sitemodel1 <- lm(difflet ~ site, data = sesame)
sitemodel2 <- lm(diffnumb ~ site, data = sesame)
summary(sitemodel1)
summary(sitemodel2)
```


Question 3 Work:
Can we accurately predict how studentsâ€™ test scores might change based on their demographic characteristics and how much they watch sesame street?

My first attempt is through using regression trees with the target of predicting both 
difflet and diffnum based off of the demogrpahic characteristics and how much they actually 
watch the program.

```{r}
library(tree)
library(MASS)
```

```{r }
set.seed(4)
train <- sample(1:nrow(sesame), nrow(sesame)/2) 
tree.letters <- tree(difflet ~ site + viewcat, sesame, subset = train)
summary(tree.letters)
plot(tree.letters)
text(tree.letters, pretty = 0)
```

Attempt at pruning...
```{r}
cv.letters <- cv.tree(tree.letters)
plot(cv.letters$size, cv.letters$dev, type = "b")
```
Based off of this, the CV shows that the best tree is one with 4 nodes. I made that tree below...

```{r pruned-letters}
prune.letters <- prune.tree(tree.letters, best = 4)
summary(prune.letters)
plot(prune.letters)
text(prune.letters, pretty = 0)
```



```{r }
set.seed(4)
train <- sample(1:nrow(sesame), nrow(sesame)/2) 
tree.nums <- tree(diffnumb ~ site + viewcat, sesame, subset = train)
summary(tree.nums)
plot(tree.nums)
text(tree.nums, pretty = 0)
```

```{r}
cv.numbers <- cv.tree(tree.nums)
plot(cv.numbers$size, cv.numbers$dev, type = "b")
```
Here, the optimal nodes determined by cross validation is 2.

```{r}
prune.numbers <- prune.tree(tree.nums, best = 2)
summary(prune.numbers)
plot(prune.numbers)
text(prune.numbers, pretty = 0)
```

Ok so I fit the two trees above with site (which is the level of how economically 
disadvantaged the children are) and viewcat (which is how frequently they watch
Sesame Street). 

The other way that we had proposed answering this question was through GAMs.
So this is what I worked with on those...

```{r}
#In the lab I was looking at it just did not explain why the degrees of freedom were chosen, but I did n+1 for the number of groups that there were?? But maybe that's not the right way to approach it
#There are 5 sites and 4 viewcats
library(gam)
#gam.lets <- gam(difflet ~ ns(site, 6) + ns(viewcat, 5), data = sesame1)
#gam.nums <- gam(diffnumb ~ ns(site, 6) + ns(viewcat, 5), data = sesame1)
#summary(gam.lets)
#summary(gam.nums)

#I keep getting this error
#Error in (1 - h) * qs[i] : non-numeric argument to binary operator
```



